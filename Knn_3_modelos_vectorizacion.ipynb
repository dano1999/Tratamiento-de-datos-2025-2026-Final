{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ae06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN en label (antes de limpiar):\n",
      "  train: 2\n",
      "  val:   0\n",
      "  test:  0\n",
      "\n",
      "NaN en label (después de limpiar):\n",
      "  train: 0\n",
      "  val:   0\n",
      "  test:  0\n",
      "\n",
      "Etiquetas únicas en train: ['comment' 'deny' 'query' 'support']\n",
      "\n",
      "Distribución de clases:\n",
      "\n",
      " TRAIN (total = 4877) \n",
      "comment : 3495 (0.717)\n",
      "support :  642 (0.132)\n",
      "query   :  373 (0.076)\n",
      "deny    :  367 (0.075)\n",
      "\n",
      " VAL (total = 1440) \n",
      "comment : 1174 (0.815)\n",
      "query   :  114 (0.079)\n",
      "deny    :   79 (0.055)\n",
      "support :   73 (0.051)\n",
      "\n",
      " TEST (total = 1675) \n",
      "comment : 1405 (0.839)\n",
      "support :  104 (0.062)\n",
      "deny    :  100 (0.060)\n",
      "query   :   66 (0.039)\n",
      "\n",
      "Ejemplo de texto de entrenamiento:\n",
      "France: 10 people dead after shooting at HQ of satirical weekly newspaper #CharlieHebdo, according to witnesses http://t.co/FkYxGmuS58 [SEP] MT @euronews France: 10 dead after shooting at HQ of satirical weekly #CharlieHebdo. If Zionists/Jews did this they'd be nuking Israel\n",
      "Etiqueta: comment\n",
      "\n",
      "Clases (label_encoder): ['comment' 'deny' 'query' 'support']\n",
      "\n",
      "Clase mayoritaria en TEST: comment\n",
      "Accuracy baseline (siempre 'comment') = 0.8388\n",
      "\n",
      "\n",
      "TF-IDF + KNN\n",
      "RESULTADOS KNN - TF-IDF\n",
      "k = 1 --> Accuracy validación = 0.6632\n",
      "k = 3 --> Accuracy validación = 0.7118\n",
      "k = 5 --> Accuracy validación = 0.7389\n",
      "k = 7 --> Accuracy validación = 0.7681\n",
      "k = 9 --> Accuracy validación = 0.7903\n",
      "\n",
      "Mejor número de vecinos (k) encontrado en validación: 9\n",
      "Accuracy de validación con k=9: 0.7903\n",
      "\n",
      "Accuracy en TEST con k=9: 0.8299\n",
      "\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment     0.8412    0.9879    0.9087      1405\n",
      "        deny     0.0000    0.0000    0.0000       100\n",
      "       query     0.0000    0.0000    0.0000        66\n",
      "     support     0.1000    0.0192    0.0323       104\n",
      "\n",
      "    accuracy                         0.8299      1675\n",
      "   macro avg     0.2353    0.2518    0.2352      1675\n",
      "weighted avg     0.7118    0.8299    0.7642      1675\n",
      "\n",
      "\n",
      "Ejemplo de predicciones en test (primeros 20):\n",
      "y_test_pred[:20] = ['comment' 'support' 'comment' 'comment' 'comment' 'support' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'support' 'support' 'comment'\n",
      " 'comment' 'comment' 'support' 'comment' 'comment' 'comment']\n",
      "y_test[:20]      = ['comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'query' 'comment' 'comment' 'query']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREDICCIÓN TF-IDF + KNN (primeras 10 líneas)\n",
      "Texto 0:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 1:\n",
      "   Predicción: support\n",
      "   Real:       comment\n",
      "Texto 2:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 3:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 4:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 5:\n",
      "   Predicción: support\n",
      "   Real:       comment\n",
      "Texto 6:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 7:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 8:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 9:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "\n",
      "\n",
      "TF-IDF + CNN\n",
      "ENTRENANDO RED NEURONAL CONVOLUCIONAL - TF-IDF + CNN\n",
      "Usando dispositivo: cuda\n",
      "\n",
      "Pesos de clase (para CrossEntropyLoss):\n",
      "  Clase 0 (comment): 0.3489\n",
      "  Clase 1 (deny): 3.3222\n",
      "  Clase 2 (query): 3.2688\n",
      "  Clase 3 (support): 1.8991\n",
      "Época 01/15 | Loss train = 5.2430 | Acc train = 0.2799 | Acc val = 0.0556\n",
      "Época 02/15 | Loss train = 3.0131 | Acc train = 0.2860 | Acc val = 0.1667\n",
      "Época 03/15 | Loss train = 2.3394 | Acc train = 0.2686 | Acc val = 0.5611\n",
      "Época 04/15 | Loss train = 1.9189 | Acc train = 0.2807 | Acc val = 0.0507\n",
      "Época 05/15 | Loss train = 1.6702 | Acc train = 0.2653 | Acc val = 0.0958\n",
      "Época 06/15 | Loss train = 1.5339 | Acc train = 0.2643 | Acc val = 0.8153\n",
      "Época 07/15 | Loss train = 1.4439 | Acc train = 0.2883 | Acc val = 0.8153\n",
      "Época 08/15 | Loss train = 1.4209 | Acc train = 0.3324 | Acc val = 0.0639\n",
      "Época 09/15 | Loss train = 1.4082 | Acc train = 0.3024 | Acc val = 0.8139\n",
      "Época 10/15 | Loss train = 1.4021 | Acc train = 0.3229 | Acc val = 0.7340\n",
      "Época 11/15 | Loss train = 1.3965 | Acc train = 0.3728 | Acc val = 0.1160\n",
      "Época 12/15 | Loss train = 1.3938 | Acc train = 0.3059 | Acc val = 0.0576\n",
      "Época 13/15 | Loss train = 1.3952 | Acc train = 0.3332 | Acc val = 0.7424\n",
      "Época 14/15 | Loss train = 1.3941 | Acc train = 0.3754 | Acc val = 0.7590\n",
      "Época 15/15 | Loss train = 1.3975 | Acc train = 0.3281 | Acc val = 0.6653\n",
      "\n",
      "Mejor accuracy de validación alcanzado: 0.8153\n",
      "\n",
      "Accuracy en TEST (TF-IDF + CNN) = 0.8012\n",
      "\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment     0.8382    0.9552    0.8929      1405\n",
      "        deny     0.0000    0.0000    0.0000       100\n",
      "       query     0.0000    0.0000    0.0000        66\n",
      "     support     0.0000    0.0000    0.0000       104\n",
      "\n",
      "    accuracy                         0.8012      1675\n",
      "   macro avg     0.2096    0.2388    0.2232      1675\n",
      "weighted avg     0.7031    0.8012    0.7490      1675\n",
      "\n",
      "\n",
      "Ejemplo de predicciones en test (primeros 20):\n",
      "y_test_pred[:20] = ['comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment']\n",
      "y_test[:20]      = ['comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'query' 'comment' 'comment' 'query']\n",
      "\n",
      "PREDICCIÓN TF-IDF + CNN (primeras 10 líneas)\n",
      "Texto 0:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 1:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 2:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 3:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 4:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 5:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 6:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 7:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 8:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "Texto 9:\n",
      "   Predicción: comment\n",
      "   Real:       comment\n",
      "\n",
      "\n",
      "Word2Vec + KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS KNN - Word2Vec (media embeddings)\n",
      "k = 1 --> Accuracy validación = 0.6556\n",
      "k = 3 --> Accuracy validación = 0.7743\n",
      "k = 5 --> Accuracy validación = 0.8000\n",
      "k = 7 --> Accuracy validación = 0.8097\n",
      "k = 9 --> Accuracy validación = 0.8097\n",
      "\n",
      "Mejor número de vecinos (k) encontrado en validación: 7\n",
      "Accuracy de validación con k=7: 0.8097\n",
      "\n",
      "Accuracy en TEST con k=7: 0.8364\n",
      "\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment     0.8384    0.9972    0.9109      1405\n",
      "        deny     0.0000    0.0000    0.0000       100\n",
      "       query     0.0000    0.0000    0.0000        66\n",
      "     support     0.0000    0.0000    0.0000       104\n",
      "\n",
      "    accuracy                         0.8364      1675\n",
      "   macro avg     0.2096    0.2493    0.2277      1675\n",
      "weighted avg     0.7033    0.8364    0.7641      1675\n",
      "\n",
      "\n",
      "Ejemplo de predicciones en test (primeros 20):\n",
      "y_test_pred[:20] = ['comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment']\n",
      "y_test[:20]      = ['comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'query' 'comment' 'comment' 'query']\n",
      "\n",
      "PREDICCIÓN Word2Vec + KNN (primeras 10 líneas)\n",
      "0) pred=comment  real=comment\n",
      "1) pred=comment  real=comment\n",
      "2) pred=comment  real=comment\n",
      "3) pred=comment  real=comment\n",
      "4) pred=comment  real=comment\n",
      "5) pred=comment  real=comment\n",
      "6) pred=comment  real=comment\n",
      "7) pred=comment  real=comment\n",
      "8) pred=comment  real=comment\n",
      "9) pred=comment  real=comment\n",
      "\n",
      "\n",
      "Word2Vec + CNN\n",
      "ENTRENANDO RED NEURONAL CONVOLUCIONAL - Word2Vec + CNN (mejorada)\n",
      "Usando dispositivo: cuda\n",
      "\n",
      "Pesos de clase (para CrossEntropyLoss):\n",
      "  Clase 0 (comment): 0.3489\n",
      "  Clase 1 (deny): 3.3222\n",
      "  Clase 2 (query): 3.2688\n",
      "  Clase 3 (support): 1.8991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 01/35 | Loss train = 1.7223 | Acc train = 0.2668 | Acc val = 0.4014\n",
      "Época 02/35 | Loss train = 1.4941 | Acc train = 0.2838 | Acc val = 0.5868\n",
      "Época 03/35 | Loss train = 1.4256 | Acc train = 0.3195 | Acc val = 0.1139\n",
      "Época 04/35 | Loss train = 1.4329 | Acc train = 0.2944 | Acc val = 0.4771\n",
      "Época 05/35 | Loss train = 1.4192 | Acc train = 0.3221 | Acc val = 0.3667\n",
      "Época 06/35 | Loss train = 1.3892 | Acc train = 0.3211 | Acc val = 0.5396\n",
      "Época 07/35 | Loss train = 1.3634 | Acc train = 0.3195 | Acc val = 0.4507\n",
      "Época 08/35 | Loss train = 1.3424 | Acc train = 0.3344 | Acc val = 0.6542\n",
      "Época 09/35 | Loss train = 1.3564 | Acc train = 0.3223 | Acc val = 0.5639\n",
      "Época 10/35 | Loss train = 1.3408 | Acc train = 0.3143 | Acc val = 0.6854\n",
      "Época 11/35 | Loss train = 1.3355 | Acc train = 0.3424 | Acc val = 0.6840\n",
      "Época 12/35 | Loss train = 1.3243 | Acc train = 0.3361 | Acc val = 0.6653\n",
      "Época 13/35 | Loss train = 1.3041 | Acc train = 0.3490 | Acc val = 0.7153\n",
      "Época 14/35 | Loss train = 1.3022 | Acc train = 0.3687 | Acc val = 0.4938\n",
      "Época 15/35 | Loss train = 1.2846 | Acc train = 0.3568 | Acc val = 0.5347\n",
      "Época 16/35 | Loss train = 1.2987 | Acc train = 0.3377 | Acc val = 0.4076\n",
      "Época 17/35 | Loss train = 1.2746 | Acc train = 0.3631 | Acc val = 0.4861\n",
      "Época 18/35 | Loss train = 1.2890 | Acc train = 0.3338 | Acc val = 0.4715\n",
      "Época 19/35 | Loss train = 1.2854 | Acc train = 0.3588 | Acc val = 0.6743\n",
      "Época 20/35 | Loss train = 1.2715 | Acc train = 0.3666 | Acc val = 0.4813\n",
      "Época 21/35 | Loss train = 1.2576 | Acc train = 0.3730 | Acc val = 0.5764\n",
      "Época 22/35 | Loss train = 1.2702 | Acc train = 0.3650 | Acc val = 0.4646\n",
      "Época 23/35 | Loss train = 1.2503 | Acc train = 0.3695 | Acc val = 0.4236\n",
      "Época 24/35 | Loss train = 1.2616 | Acc train = 0.3689 | Acc val = 0.5674\n",
      "Época 25/35 | Loss train = 1.2470 | Acc train = 0.3810 | Acc val = 0.6132\n",
      "Época 26/35 | Loss train = 1.2473 | Acc train = 0.3705 | Acc val = 0.4708\n",
      "Época 27/35 | Loss train = 1.2307 | Acc train = 0.3849 | Acc val = 0.5326\n",
      "Época 28/35 | Loss train = 1.2426 | Acc train = 0.3834 | Acc val = 0.5806\n",
      "Época 29/35 | Loss train = 1.2094 | Acc train = 0.3853 | Acc val = 0.6090\n",
      "Época 30/35 | Loss train = 1.2107 | Acc train = 0.3812 | Acc val = 0.4694\n",
      "Época 31/35 | Loss train = 1.2139 | Acc train = 0.3896 | Acc val = 0.3750\n",
      "Época 32/35 | Loss train = 1.2080 | Acc train = 0.3814 | Acc val = 0.4799\n",
      "Época 33/35 | Loss train = 1.1914 | Acc train = 0.4007 | Acc val = 0.4299\n",
      "Época 34/35 | Loss train = 1.2220 | Acc train = 0.3697 | Acc val = 0.4361\n",
      "Época 35/35 | Loss train = 1.2097 | Acc train = 0.3853 | Acc val = 0.5042\n",
      "\n",
      "Mejor accuracy de validación alcanzado: 0.7153\n",
      "\n",
      "Accuracy en TEST (Word2Vec + CNN (mejorada)) = 0.5946\n",
      "\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment     0.8580    0.6925    0.7664      1405\n",
      "        deny     0.0488    0.0800    0.0606       100\n",
      "       query     0.0402    0.2273    0.0683        66\n",
      "     support     0.0000    0.0000    0.0000       104\n",
      "\n",
      "    accuracy                         0.5946      1675\n",
      "   macro avg     0.2368    0.2499    0.2238      1675\n",
      "weighted avg     0.7242    0.5946    0.6492      1675\n",
      "\n",
      "\n",
      "Ejemplo de predicciones en test (primeros 20):\n",
      "y_test_pred[:20] = ['comment' 'query' 'query' 'comment' 'query' 'comment' 'query' 'query'\n",
      " 'query' 'deny' 'deny' 'query' 'deny' 'comment' 'comment' 'deny' 'query'\n",
      " 'query' 'comment' 'deny']\n",
      "y_test[:20]      = ['comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'query' 'comment' 'comment' 'query']\n",
      "\n",
      "PREDICCIÓN Word2Vec + CNN (primeras 10 líneas)\n",
      "0) pred=comment  real=comment\n",
      "1) pred=query  real=comment\n",
      "2) pred=query  real=comment\n",
      "3) pred=comment  real=comment\n",
      "4) pred=query  real=comment\n",
      "5) pred=comment  real=comment\n",
      "6) pred=query  real=comment\n",
      "7) pred=query  real=comment\n",
      "8) pred=query  real=comment\n",
      "9) pred=deny  real=comment\n",
      "\n",
      "\n",
      "EMBEDDINGS (Sentence-BERT) + KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 153/153 [00:01<00:00, 114.56it/s]\n",
      "Batches: 100%|██████████| 45/45 [00:00<00:00, 124.50it/s]\n",
      "Batches: 100%|██████████| 53/53 [00:00<00:00, 122.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS KNN - Embeddings contextuales (Sentence-BERT)\n",
      "k = 1 --> Accuracy validación = 0.6465\n",
      "k = 3 --> Accuracy validación = 0.6931\n",
      "k = 5 --> Accuracy validación = 0.7701\n",
      "k = 7 --> Accuracy validación = 0.7868\n",
      "k = 9 --> Accuracy validación = 0.8035\n",
      "\n",
      "Mejor número de vecinos (k) encontrado en validación: 9\n",
      "Accuracy de validación con k=9: 0.8035\n",
      "\n",
      "Accuracy en TEST con k=9: 0.8304\n",
      "\n",
      "Classification report (TEST):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment     0.8395    0.9900    0.9086      1405\n",
      "        deny     0.0000    0.0000    0.0000       100\n",
      "       query     0.0000    0.0000    0.0000        66\n",
      "     support     0.0000    0.0000    0.0000       104\n",
      "\n",
      "    accuracy                         0.8304      1675\n",
      "   macro avg     0.2099    0.2475    0.2271      1675\n",
      "weighted avg     0.7042    0.8304    0.7621      1675\n",
      "\n",
      "\n",
      "Ejemplo de predicciones en test (primeros 20):\n",
      "y_test_pred[:20] = ['comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment']\n",
      "y_test[:20]      = ['comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'query' 'comment' 'comment' 'query']\n",
      "\n",
      "PREDICCIÓN BERT + KNN (primeras 10 líneas)\n",
      "0) pred=comment  real=comment\n",
      "1) pred=comment  real=comment\n",
      "2) pred=comment  real=comment\n",
      "3) pred=comment  real=comment\n",
      "4) pred=comment  real=comment\n",
      "5) pred=comment  real=comment\n",
      "6) pred=comment  real=comment\n",
      "7) pred=comment  real=comment\n",
      "8) pred=comment  real=comment\n",
      "9) pred=comment  real=comment\n",
      "\n",
      "\n",
      "BERT Embeddings + CNN \n",
      "ENTRENANDO RED NEURONAL CONVOLUCIONAL - Sentence-BERT + CNN\n",
      "Usando dispositivo: cuda\n",
      "\n",
      "Pesos de clase (para CrossEntropyLoss):\n",
      "  Clase 0 (comment): 0.3489\n",
      "  Clase 1 (deny): 3.3222\n",
      "  Clase 2 (query): 3.2688\n",
      "  Clase 3 (support): 1.8991\n",
      "Época 01/30 | Loss train = 1.8033 | Acc train = 0.2690 | Acc val = 0.3056\n",
      "Época 02/30 | Loss train = 1.5315 | Acc train = 0.2770 | Acc val = 0.5368\n",
      "Época 03/30 | Loss train = 1.4521 | Acc train = 0.2873 | Acc val = 0.7972\n",
      "Época 04/30 | Loss train = 1.4345 | Acc train = 0.2963 | Acc val = 0.1590\n",
      "Época 05/30 | Loss train = 1.3962 | Acc train = 0.3065 | Acc val = 0.8125\n",
      "Época 06/30 | Loss train = 1.3947 | Acc train = 0.3147 | Acc val = 0.1340\n",
      "Época 07/30 | Loss train = 1.3918 | Acc train = 0.3084 | Acc val = 0.1451\n",
      "Época 08/30 | Loss train = 1.3868 | Acc train = 0.3131 | Acc val = 0.6472\n",
      "Época 09/30 | Loss train = 1.3767 | Acc train = 0.3258 | Acc val = 0.0924\n",
      "Época 10/30 | Loss train = 1.3591 | Acc train = 0.3041 | Acc val = 0.1806\n",
      "Época 11/30 | Loss train = 1.3654 | Acc train = 0.3311 | Acc val = 0.7438\n",
      "Época 12/30 | Loss train = 1.3643 | Acc train = 0.3289 | Acc val = 0.5806\n",
      "Época 13/30 | Loss train = 1.3498 | Acc train = 0.3217 | Acc val = 0.2444\n",
      "Época 14/30 | Loss train = 1.3486 | Acc train = 0.2965 | Acc val = 0.7535\n",
      "Época 15/30 | Loss train = 1.3395 | Acc train = 0.3342 | Acc val = 0.5118\n",
      "Época 16/30 | Loss train = 1.3435 | Acc train = 0.3180 | Acc val = 0.3715\n",
      "Época 17/30 | Loss train = 1.3248 | Acc train = 0.3139 | Acc val = 0.7250\n",
      "Época 18/30 | Loss train = 1.3010 | Acc train = 0.3277 | Acc val = 0.4701\n",
      "Época 19/30 | Loss train = 1.3052 | Acc train = 0.3441 | Acc val = 0.3167\n",
      "Época 20/30 | Loss train = 1.3018 | Acc train = 0.3486 | Acc val = 0.3896\n",
      "Época 21/30 | Loss train = 1.2861 | Acc train = 0.3447 | Acc val = 0.4104\n",
      "Época 22/30 | Loss train = 1.2704 | Acc train = 0.3379 | Acc val = 0.2743\n",
      "Época 23/30 | Loss train = 1.2623 | Acc train = 0.3418 | Acc val = 0.2486\n",
      "Época 24/30 | Loss train = 1.2598 | Acc train = 0.3529 | Acc val = 0.6833\n",
      "Época 25/30 | Loss train = 1.2435 | Acc train = 0.3324 | Acc val = 0.7194\n",
      "Época 26/30 | Loss train = 1.2405 | Acc train = 0.3582 | Acc val = 0.4493\n",
      "Época 27/30 | Loss train = 1.2240 | Acc train = 0.3451 | Acc val = 0.5306\n",
      "Época 28/30 | Loss train = 1.2043 | Acc train = 0.3504 | Acc val = 0.6625\n",
      "Época 29/30 | Loss train = 1.1810 | Acc train = 0.3658 | Acc val = 0.5368\n",
      "Época 30/30 | Loss train = 1.1641 | Acc train = 0.3662 | Acc val = 0.6521\n",
      "\n",
      "Mejor accuracy de validación alcanzado: 0.8125\n",
      "\n",
      "Accuracy en TEST (Sentence-BERT + CNN) = 0.7373\n",
      "\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment     0.8440    0.8705    0.8570      1405\n",
      "        deny     0.2500    0.0200    0.0370       100\n",
      "       query     0.0125    0.0152    0.0137        66\n",
      "     support     0.0652    0.0865    0.0744       104\n",
      "\n",
      "    accuracy                         0.7373      1675\n",
      "   macro avg     0.2929    0.2480    0.2455      1675\n",
      "weighted avg     0.7274    0.7373    0.7263      1675\n",
      "\n",
      "\n",
      "Ejemplo de predicciones en test (primeros 20):\n",
      "y_test_pred[:20] = ['comment' 'comment' 'comment' 'comment' 'query' 'support' 'support'\n",
      " 'comment' 'support' 'comment' 'support' 'support' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment']\n",
      "y_test[:20]      = ['comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'comment' 'comment' 'comment' 'comment' 'comment'\n",
      " 'comment' 'comment' 'query' 'comment' 'comment' 'query']\n",
      "\n",
      "PREDICCIÓN BERT + CNN (primeras 10 líneas)\n",
      "0) pred=comment  real=comment\n",
      "1) pred=comment  real=comment\n",
      "2) pred=comment  real=comment\n",
      "3) pred=comment  real=comment\n",
      "4) pred=query  real=comment\n",
      "5) pred=support  real=comment\n",
      "6) pred=support  real=comment\n",
      "7) pred=comment  real=comment\n",
      "8) pred=support  real=comment\n",
      "9) pred=comment  real=comment\n",
      "\n",
      "\n",
      "TRANSFORMER PREENTRENADO + FINE-TUNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo para Transformer: cuda\n",
      "[Transformer] Época 1/3 | Loss train = 0.8381 | Acc train = 0.7131 | Acc val = 0.8292\n",
      "[Transformer] Época 2/3 | Loss train = 0.7259 | Acc train = 0.7490 | Acc val = 0.8299\n",
      "[Transformer] Época 3/3 | Loss train = 0.5857 | Acc train = 0.7962 | Acc val = 0.8146\n",
      "\n",
      "Mejor accuracy de validación (Transformer) = 0.8299\n",
      "\n",
      "Accuracy en TEST (Transformer fine-tuned: distilbert-base-uncased) = 0.8239\n",
      "\n",
      "Classification report (TEST) - Transformer fine-tuned:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment     0.8531    0.9552    0.9013      1405\n",
      "        deny     0.3333    0.0700    0.1157       100\n",
      "       query     0.3827    0.4697    0.4218        66\n",
      "     support     0.0000    0.0000    0.0000       104\n",
      "\n",
      "    accuracy                         0.8239      1675\n",
      "   macro avg     0.3923    0.3737    0.3597      1675\n",
      "weighted avg     0.7506    0.8239    0.7795      1675\n",
      "\n",
      "\n",
      "\n",
      "RESUMEN FINAL - KNN\n",
      "TF-IDF (KNN):        mejor k = 9,  accuracy test = 0.8299\n",
      "Word2Vec (KNN):      mejor k = 7,    accuracy test = 0.8364\n",
      "Sentence-BERT (KNN): mejor k = 9,   accuracy test = 0.8304\n",
      "\n",
      "RESUMEN FINAL - CNN\n",
      "TF-IDF  + CNN:        accuracy test = 0.8012\n",
      "Word2Vec + CNN:       accuracy test = 0.5946\n",
      "Sentence-BERT + CNN:  accuracy test = 0.7373\n",
      "\n",
      "Baseline mayoría ('comment') en TEST: accuracy = 0.8388\n",
      "\n",
      "RESUMEN FINAL - TRANSFORMER FINE-TUNED\n",
      "Transformer (distilbert-base-uncased): accuracy test = 0.8239\n",
      "\n",
      "\n",
      "BASELINE LÉXICA SENCILLA (EXTENSIÓN)\n",
      "\n",
      "Resultados baseline léxica sobre TEST:\n",
      "Accuracy baseline léxica = 0.3684\n",
      "\n",
      "Classification report (TEST) - Baseline léxica:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment     0.8386    0.3587    0.5025      1405\n",
      "        deny     0.2394    0.5100    0.3259       100\n",
      "       query     0.0796    0.8939    0.1462        66\n",
      "     support     0.0250    0.0288    0.0268       104\n",
      "\n",
      "    accuracy                         0.3684      1675\n",
      "   macro avg     0.2957    0.4479    0.2503      1675\n",
      "weighted avg     0.7224    0.3684    0.4484      1675\n",
      "\n",
      "\n",
      "Ejemplo de predicciones (primeros 20 ejemplos del TEST):\n",
      "0) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "1) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "2) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "3) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "4) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "5) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "6) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "7) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "8) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "9) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "10) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "11) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "12) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "13) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "14) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "15) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "16) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = query\n",
      "   pred_lex = query\n",
      "17) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "18) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = comment\n",
      "   pred_lex = query\n",
      "19) texto='#Breaking: Pentagon releases video of the “mother of all bom'...\n",
      "   real     = query\n",
      "   pred_lex = query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Pablo\\OneDrive\\Desktop\\PROYECTO TRATAMIENTO DE DATOS\\Tratamiento-de-datos-2025-2026\\rumourenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "train_path = \"data/datasets/rumoureval2019_train.csv\"\n",
    "val_path   = \"data/datasets/rumoureval2019_val.csv\"\n",
    "test_path  = \"data/datasets/rumoureval2019_test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df   = pd.read_csv(val_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "print(\"NaN en label (antes de limpiar):\")\n",
    "print(\"  train:\", train_df[\"label\"].isna().sum())\n",
    "print(\"  val:  \", val_df[\"label\"].isna().sum())\n",
    "print(\"  test: \", test_df[\"label\"].isna().sum())\n",
    "\n",
    "train_df = train_df.dropna(subset=[\"label\"])\n",
    "val_df   = val_df.dropna(subset=[\"label\"])\n",
    "test_df  = test_df.dropna(subset=[\"label\"])\n",
    "\n",
    "print(\"\\nNaN en label (después de limpiar):\")\n",
    "print(\"  train:\", train_df[\"label\"].isna().sum())\n",
    "print(\"  val:  \", val_df[\"label\"].isna().sum())\n",
    "print(\"  test: \", test_df[\"label\"].isna().sum())\n",
    "\n",
    "print(\"\\nEtiquetas únicas en train:\", train_df[\"label\"].unique())\n",
    "\n",
    "print(\"\\nDistribución de clases:\")\n",
    "for name, df in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
    "    counts = df[\"label\"].value_counts()\n",
    "    total = counts.sum()\n",
    "    print(f\"\\n {name.upper()} (total = {total}) \")\n",
    "    for label, c in counts.items():\n",
    "        print(f\"{label:8s}: {c:4d} ({c/total:.3f})\")\n",
    "\n",
    "def concat_text_row(row):\n",
    "    src = row.get(\"source_text\", \"\")\n",
    "    rep = row.get(\"reply_text\", \"\")\n",
    "    src = \"\" if pd.isna(src) else str(src)\n",
    "    rep = \"\" if pd.isna(rep) else str(rep)\n",
    "    return (src + \" [SEP] \" + rep).strip()\n",
    "\n",
    "X_train_text = train_df.apply(concat_text_row, axis=1).tolist()\n",
    "y_train = train_df[\"label\"].values         \n",
    "\n",
    "X_val_text = val_df.apply(concat_text_row, axis=1).tolist()\n",
    "y_val = val_df[\"label\"].values\n",
    "\n",
    "X_test_text = test_df.apply(concat_text_row, axis=1).tolist()\n",
    "y_test = test_df[\"label\"].values\n",
    "\n",
    "print(\"\\nEjemplo de texto de entrenamiento:\")\n",
    "print(X_train_text[0])\n",
    "print(\"Etiqueta:\", y_train[0])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_idx = label_encoder.fit_transform(y_train)\n",
    "y_val_idx   = label_encoder.transform(y_val)\n",
    "y_test_idx  = label_encoder.transform(y_test)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(\"\\nClases (label_encoder):\", label_encoder.classes_)\n",
    "\n",
    "major_class = Counter(y_test).most_common(1)[0][0]\n",
    "baseline_acc = np.mean(y_test == major_class)\n",
    "print(f\"\\nClase mayoritaria en TEST: {major_class}\")\n",
    "print(f\"Accuracy baseline (siempre '{major_class}') = {baseline_acc:.4f}\")\n",
    "\n",
    "\n",
    "def train_and_evaluate_knn(X_train_vec, y_train,\n",
    "                           X_val_vec, y_val,\n",
    "                           X_test_vec, y_test,\n",
    "                           k_values=[1, 3, 5, 7, 9],\n",
    "                           title=\"\"):\n",
    "    print(\"RESULTADOS KNN -\", title)\n",
    "\n",
    "    best_k = None\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train_vec, y_train)\n",
    "        y_val_pred = knn.predict(X_val_vec)\n",
    "        acc_val = accuracy_score(y_val, y_val_pred)\n",
    "        print(f\"k = {k} --> Accuracy validación = {acc_val:.4f}\")\n",
    "\n",
    "        if acc_val > best_acc:\n",
    "            best_acc = acc_val\n",
    "            best_k = k\n",
    "\n",
    "    print(\"\\nMejor número de vecinos (k) encontrado en validación:\", best_k)\n",
    "    print(f\"Accuracy de validación con k={best_k}: {best_acc:.4f}\")\n",
    "\n",
    "    final_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    final_knn.fit(X_train_vec, y_train)\n",
    "\n",
    "    y_test_pred = final_knn.predict(X_test_vec)\n",
    "    acc_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"\\nAccuracy en TEST con k={best_k}: {acc_test:.4f}\")\n",
    "    print(\"\\nClassification report (TEST):\")\n",
    "    print(classification_report(y_test, y_test_pred, digits=4))\n",
    "\n",
    "    print(\"\\nEjemplo de predicciones en test (primeros 20):\")\n",
    "    print(\"y_test_pred[:20] =\", y_test_pred[:20])\n",
    "    print(\"y_test[:20]      =\", y_test[:20])\n",
    "\n",
    "    return final_knn, best_k, acc_test\n",
    "\n",
    "\n",
    "class ConvNet1D(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, num_classes, dropout=0.3):\n",
    "        super(ConvNet1D, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=1,   out_channels=64, kernel_size=5, padding=2)\n",
    "        self.bn1   = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=64,  out_channels=64, kernel_size=5, padding=2)\n",
    "        self.bn2   = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=64,  out_channels=64, kernel_size=5, padding=2)\n",
    "        self.bn3   = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(in_channels=64,  out_channels=64, kernel_size=5, padding=2)\n",
    "        self.bn4   = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)           # (B, 1, L)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # (B, 64, L)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # (B, 64, L)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # (B, 64, L)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))  # (B, 64, L)\n",
    "\n",
    "        x = self.global_pool(x)      # (B, 64, 1)\n",
    "        x = x.squeeze(-1)            # (B, 64)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)               # (B, num_classes)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate_cnn(\n",
    "    X_train, y_train_idx,\n",
    "    X_val, y_val_idx,\n",
    "    X_test, y_test_idx,\n",
    "    label_encoder,\n",
    "    title=\"CNN\",\n",
    "    num_epochs=20,\n",
    "    batch_size=32,\n",
    "    lr=5e-4,\n",
    "    dropout=0.3,\n",
    "    device=None\n",
    "):\n",
    "\n",
    "    print(\"ENTRENANDO RED NEURONAL CONVOLUCIONAL -\", title)\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Usando dispositivo:\", device)\n",
    "\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    X_val   = np.asarray(X_val,   dtype=np.float32)\n",
    "    X_test  = np.asarray(X_test,  dtype=np.float32)\n",
    "\n",
    "    y_train_idx = np.asarray(y_train_idx, dtype=np.int64)\n",
    "    y_val_idx   = np.asarray(y_val_idx,   dtype=np.int64)\n",
    "    y_test_idx  = np.asarray(y_test_idx,  dtype=np.int64)\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "\n",
    "    train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train_idx))\n",
    "    val_dataset   = TensorDataset(torch.from_numpy(X_val),   torch.from_numpy(y_val_idx))\n",
    "    test_dataset  = TensorDataset(torch.from_numpy(X_test),  torch.from_numpy(y_test_idx))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    class_weights_np = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.arange(num_classes),\n",
    "        y=y_train_idx\n",
    "    )\n",
    "    class_weights = torch.tensor(class_weights_np, dtype=torch.float32).to(device)\n",
    "    print(\"\\nPesos de clase (para CrossEntropyLoss):\")\n",
    "    for idx, w in enumerate(class_weights_np):\n",
    "        print(f\"  Clase {idx} ({label_encoder.classes_[idx]}): {w:.4f}\")\n",
    "\n",
    "    model = ConvNet1D(input_dim=input_dim, num_classes=num_classes, dropout=dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state_dict = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * batch_X.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_train += (preds == batch_y).sum().item()\n",
    "            total_train += batch_X.size(0)\n",
    "\n",
    "        train_loss = running_loss / total_train\n",
    "        train_acc = correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.inference_mode():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X = batch_X.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_val += (preds == batch_y).sum().item()\n",
    "                total_val += batch_X.size(0)\n",
    "\n",
    "        val_acc = correct_val / total_val\n",
    "\n",
    "        print(f\"Época {epoch:02d}/{num_epochs} | \"\n",
    "              f\"Loss train = {train_loss:.4f} | \"\n",
    "              f\"Acc train = {train_acc:.4f} | \"\n",
    "              f\"Acc val = {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state_dict = model.state_dict()\n",
    "\n",
    "    print(f\"\\nMejor accuracy de validación alcanzado: {best_val_acc:.4f}\")\n",
    "\n",
    "    if best_state_dict is not None:\n",
    "        model.load_state_dict(best_state_dict)\n",
    "\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    with torch.inference_mode():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_true.append(batch_y.numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_true  = np.concatenate(all_true)\n",
    "\n",
    "    y_test_pred_labels = label_encoder.inverse_transform(all_preds)\n",
    "    y_test_true_labels = label_encoder.inverse_transform(all_true)\n",
    "\n",
    "    acc_test = accuracy_score(y_test_true_labels, y_test_pred_labels)\n",
    "    print(f\"\\nAccuracy en TEST ({title}) = {acc_test:.4f}\")\n",
    "    print(\"\\nClassification report (TEST):\")\n",
    "    print(classification_report(y_test_true_labels, y_test_pred_labels, digits=4))\n",
    "\n",
    "    print(\"\\nEjemplo de predicciones en test (primeros 20):\")\n",
    "    print(\"y_test_pred[:20] =\", y_test_pred_labels[:20])\n",
    "    print(\"y_test[:20]      =\", y_test_true_labels[:20])\n",
    "\n",
    "    return model, acc_test, y_test_pred_labels\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\nTF-IDF + KNN\")\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "X_val_tfidf   = tfidf_vectorizer.transform(X_val_text)\n",
    "X_test_tfidf  = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "knn_tfidf, best_k_tfidf, acc_test_tfidf = train_and_evaluate_knn(\n",
    "    X_train_tfidf, y_train,\n",
    "    X_val_tfidf, y_val,\n",
    "    X_test_tfidf, y_test,\n",
    "    k_values=[1, 3, 5, 7, 9],\n",
    "    title=\"TF-IDF\"\n",
    ")\n",
    "\n",
    "y_pred_test = knn_tfidf.predict(X_test_tfidf)\n",
    "print(\"\\nPREDICCIÓN TF-IDF + KNN (primeras 10 líneas)\")\n",
    "for i in range(10):\n",
    "    print(f\"Texto {i}:\")\n",
    "    print(\"   Predicción:\", y_pred_test[i])\n",
    "    print(\"   Real:      \", y_test[i])\n",
    "\n",
    "\n",
    "print(\"\\n\\nTF-IDF + CNN\")\n",
    "\n",
    "scaler_tfidf = StandardScaler(with_mean=False)\n",
    "X_train_tfidf_scaled = scaler_tfidf.fit_transform(X_train_tfidf)\n",
    "X_val_tfidf_scaled   = scaler_tfidf.transform(X_val_tfidf)\n",
    "X_test_tfidf_scaled  = scaler_tfidf.transform(X_test_tfidf)\n",
    "\n",
    "X_train_tfidf_dense = X_train_tfidf_scaled.toarray()\n",
    "X_val_tfidf_dense   = X_val_tfidf_scaled.toarray()\n",
    "X_test_tfidf_dense  = X_test_tfidf_scaled.toarray()\n",
    "\n",
    "cnn_tfidf, acc_test_tfidf_cnn, y_pred_test_tfidf_cnn = train_and_evaluate_cnn(\n",
    "    X_train_tfidf_dense, y_train_idx,\n",
    "    X_val_tfidf_dense,   y_val_idx,\n",
    "    X_test_tfidf_dense,  y_test_idx,\n",
    "    label_encoder,\n",
    "    title=\"TF-IDF + CNN\",\n",
    "    num_epochs=15,       \n",
    "    batch_size=32,\n",
    "    lr=5e-4,\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "print(\"\\nPREDICCIÓN TF-IDF + CNN (primeras 10 líneas)\")\n",
    "for i in range(10):\n",
    "    print(f\"Texto {i}:\")\n",
    "    print(\"   Predicción:\", y_pred_test_tfidf_cnn[i])\n",
    "    print(\"   Real:      \", y_test[i])\n",
    "\n",
    "\n",
    "print(\"\\n\\nWord2Vec + KNN\")\n",
    "\n",
    "def simple_tokenize(text):\n",
    "    return str(text).lower().split()\n",
    "\n",
    "train_tokens = [simple_tokenize(t) for t in X_train_text]\n",
    "val_tokens   = [simple_tokenize(t) for t in X_val_text]\n",
    "test_tokens  = [simple_tokenize(t) for t in X_test_text]\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=train_tokens,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    sg=1\n",
    ")\n",
    "\n",
    "word_vectors = w2v_model.wv\n",
    "\n",
    "def document_embedding(tokens, word_vectors, dim=100):\n",
    "    vecs = []\n",
    "    for tok in tokens:\n",
    "        if tok in word_vectors:\n",
    "            vecs.append(word_vectors[tok])\n",
    "    if len(vecs) == 0:\n",
    "        return np.zeros(dim)\n",
    "    else:\n",
    "        return np.mean(vecs, axis=0)\n",
    "\n",
    "def build_doc_matrix(list_of_tokens, word_vectors, dim=100):\n",
    "    return np.vstack([\n",
    "        document_embedding(toks, word_vectors, dim)\n",
    "        for toks in list_of_tokens\n",
    "    ])\n",
    "\n",
    "X_train_w2v = build_doc_matrix(train_tokens, word_vectors, dim=100)\n",
    "X_val_w2v   = build_doc_matrix(val_tokens,   word_vectors, dim=100)\n",
    "X_test_w2v  = build_doc_matrix(test_tokens,  word_vectors, dim=100)\n",
    "\n",
    "knn_w2v, best_k_w2v, acc_test_w2v = train_and_evaluate_knn(\n",
    "    X_train_w2v, y_train,\n",
    "    X_val_w2v, y_val,\n",
    "    X_test_w2v, y_test,\n",
    "    k_values=[1, 3, 5, 7, 9],\n",
    "    title=\"Word2Vec (media embeddings)\"\n",
    ")\n",
    "\n",
    "y_pred_test_w2v = knn_w2v.predict(X_test_w2v)\n",
    "print(\"\\nPREDICCIÓN Word2Vec + KNN (primeras 10 líneas)\")\n",
    "for i in range(10):\n",
    "    print(f\"{i}) pred={y_pred_test_w2v[i]}  real={y_test[i]}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\nWord2Vec + CNN\")\n",
    "\n",
    "scaler_w2v = StandardScaler()\n",
    "X_train_w2v_scaled = scaler_w2v.fit_transform(X_train_w2v)\n",
    "X_val_w2v_scaled   = scaler_w2v.transform(X_val_w2v)\n",
    "X_test_w2v_scaled  = scaler_w2v.transform(X_test_w2v)\n",
    "\n",
    "cnn_w2v, acc_test_w2v_cnn, y_pred_test_w2v_cnn = train_and_evaluate_cnn(\n",
    "    X_train_w2v_scaled, y_train_idx,\n",
    "    X_val_w2v_scaled,   y_val_idx,\n",
    "    X_test_w2v_scaled,  y_test_idx,\n",
    "    label_encoder,\n",
    "    title=\"Word2Vec + CNN (mejorada)\",\n",
    "    num_epochs=35,       \n",
    "    batch_size=32,\n",
    "    lr=3e-4,             \n",
    "    dropout=0.4\n",
    ")\n",
    "\n",
    "print(\"\\nPREDICCIÓN Word2Vec + CNN (primeras 10 líneas)\")\n",
    "for i in range(10):\n",
    "    print(f\"{i}) pred={y_pred_test_w2v_cnn[i]}  real={y_test[i]}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\nEMBEDDINGS (Sentence-BERT) + KNN\")\n",
    "\n",
    "bert_model_st = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "X_train_bert = bert_model_st.encode(X_train_text, batch_size=32, show_progress_bar=True)\n",
    "X_val_bert   = bert_model_st.encode(X_val_text,   batch_size=32, show_progress_bar=True)\n",
    "X_test_bert  = bert_model_st.encode(X_test_text,  batch_size=32, show_progress_bar=True)\n",
    "\n",
    "knn_bert, best_k_bert, acc_test_bert = train_and_evaluate_knn(\n",
    "    X_train_bert, y_train,\n",
    "    X_val_bert,   y_val,\n",
    "    X_test_bert,  y_test,\n",
    "    k_values=[1, 3, 5, 7, 9],\n",
    "    title=\"Embeddings contextuales (Sentence-BERT)\"\n",
    ")\n",
    "\n",
    "y_pred_test_bert = knn_bert.predict(X_test_bert)\n",
    "print(\"\\nPREDICCIÓN BERT + KNN (primeras 10 líneas)\")\n",
    "for i in range(10):\n",
    "    print(f\"{i}) pred={y_pred_test_bert[i]}  real={y_test[i]}\")\n",
    "\n",
    "print(\"\\n\\nBERT Embeddings + CNN \")\n",
    "\n",
    "scaler_bert = StandardScaler()\n",
    "X_train_bert_scaled = scaler_bert.fit_transform(X_train_bert)\n",
    "X_val_bert_scaled   = scaler_bert.transform(X_val_bert)\n",
    "X_test_bert_scaled  = scaler_bert.transform(X_test_bert)\n",
    "\n",
    "cnn_bert, acc_test_bert_cnn, y_pred_test_bert_cnn = train_and_evaluate_cnn(\n",
    "    X_train_bert_scaled, y_train_idx,\n",
    "    X_val_bert_scaled,   y_val_idx,\n",
    "    X_test_bert_scaled,  y_test_idx,\n",
    "    label_encoder,\n",
    "    title=\"Sentence-BERT + CNN\",\n",
    "    num_epochs=30,       \n",
    "    batch_size=32,\n",
    "    lr=5e-4,\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "print(\"\\nPREDICCIÓN BERT + CNN (primeras 10 líneas)\")\n",
    "for i in range(10):\n",
    "    print(f\"{i}) pred={y_pred_test_bert_cnn[i]}  real={y_test[i]}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\nTRANSFORMER PREENTRENADO + FINE-TUNING\")\n",
    "\n",
    "transformer_model_name = \"distilbert-base-uncased\"\n",
    "tokenizer_hf = AutoTokenizer.from_pretrained(transformer_model_name)\n",
    "\n",
    "def tokenize_batch_hf(texts, tokenizer, max_length=128):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "train_encodings_hf = tokenize_batch_hf(X_train_text, tokenizer_hf)\n",
    "val_encodings_hf   = tokenize_batch_hf(X_val_text,   tokenizer_hf)\n",
    "test_encodings_hf  = tokenize_batch_hf(X_test_text,  tokenizer_hf)\n",
    "\n",
    "class RumourEvalHFDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_dataset_hf = RumourEvalHFDataset(train_encodings_hf, y_train_idx)\n",
    "val_dataset_hf   = RumourEvalHFDataset(val_encodings_hf,   y_val_idx)\n",
    "test_dataset_hf  = RumourEvalHFDataset(test_encodings_hf,  y_test_idx)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Dispositivo para Transformer:\", device)\n",
    "\n",
    "model_hf = AutoModelForSequenceClassification.from_pretrained(\n",
    "    transformer_model_name,\n",
    "    num_labels=num_classes\n",
    ").to(device)\n",
    "\n",
    "optimizer_hf = AdamW(model_hf.parameters(), lr=2e-5)\n",
    "\n",
    "train_loader_hf = DataLoader(train_dataset_hf, batch_size=16, shuffle=True)\n",
    "val_loader_hf   = DataLoader(val_dataset_hf,   batch_size=32, shuffle=False)\n",
    "test_loader_hf  = DataLoader(test_dataset_hf,  batch_size=32, shuffle=False)\n",
    "\n",
    "num_epochs_hf = 3\n",
    "best_val_acc_hf = 0.0\n",
    "best_state_dict_hf = None\n",
    "\n",
    "for epoch in range(1, num_epochs_hf + 1):\n",
    "    model_hf.train()\n",
    "    total_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for batch in train_loader_hf:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        optimizer_hf.zero_grad()\n",
    "        outputs = model_hf(**batch)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_hf.step()\n",
    "\n",
    "        total_loss += loss.item() * batch[\"labels\"].size(0)\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        correct_train += (preds == batch[\"labels\"]).sum().item()\n",
    "        total_train += batch[\"labels\"].size(0)\n",
    "\n",
    "    train_loss = total_loss / total_train\n",
    "    train_acc = correct_train / total_train\n",
    "\n",
    "    model_hf.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch in val_loader_hf:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model_hf(**batch)\n",
    "            logits = outputs.logits\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            correct_val += (preds == batch[\"labels\"]).sum().item()\n",
    "            total_val += batch[\"labels\"].size(0)\n",
    "\n",
    "    val_acc = correct_val / total_val\n",
    "\n",
    "    print(f\"[Transformer] Época {epoch}/{num_epochs_hf} | \"\n",
    "          f\"Loss train = {train_loss:.4f} | Acc train = {train_acc:.4f} | Acc val = {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc_hf:\n",
    "        best_val_acc_hf = val_acc\n",
    "        best_state_dict_hf = model_hf.state_dict()\n",
    "\n",
    "print(f\"\\nMejor accuracy de validación (Transformer) = {best_val_acc_hf:.4f}\")\n",
    "\n",
    "if best_state_dict_hf is not None:\n",
    "    model_hf.load_state_dict(best_state_dict_hf)\n",
    "\n",
    "model_hf.eval()\n",
    "all_preds_hf = []\n",
    "all_true_hf = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for batch in test_loader_hf:\n",
    "        labels = batch[\"labels\"].numpy().copy()\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model_hf(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds = logits.argmax(dim=-1).cpu().numpy()\n",
    "        all_preds_hf.append(preds)\n",
    "        all_true_hf.append(labels)\n",
    "\n",
    "all_preds_hf = np.concatenate(all_preds_hf)\n",
    "all_true_hf  = np.concatenate(all_true_hf)\n",
    "\n",
    "acc_test_transformer = accuracy_score(all_true_hf, all_preds_hf)\n",
    "print(f\"\\nAccuracy en TEST (Transformer fine-tuned: {transformer_model_name}) = {acc_test_transformer:.4f}\")\n",
    "\n",
    "y_test_pred_labels_transformer = label_encoder.inverse_transform(all_preds_hf)\n",
    "y_test_true_labels = label_encoder.inverse_transform(all_true_hf)\n",
    "\n",
    "print(\"\\nClassification report (TEST) - Transformer fine-tuned:\")\n",
    "print(classification_report(y_test_true_labels, y_test_pred_labels_transformer, digits=4))\n",
    "\n",
    "\n",
    "print(\"\\n\\nRESUMEN FINAL - KNN\")\n",
    "print(f\"TF-IDF (KNN):        mejor k = {best_k_tfidf},  accuracy test = {acc_test_tfidf:.4f}\")\n",
    "print(f\"Word2Vec (KNN):      mejor k = {best_k_w2v},    accuracy test = {acc_test_w2v:.4f}\")\n",
    "print(f\"Sentence-BERT (KNN): mejor k = {best_k_bert},   accuracy test = {acc_test_bert:.4f}\")\n",
    "\n",
    "print(\"\\nRESUMEN FINAL - CNN\")\n",
    "print(f\"TF-IDF  + CNN:        accuracy test = {acc_test_tfidf_cnn:.4f}\")\n",
    "print(f\"Word2Vec + CNN:       accuracy test = {acc_test_w2v_cnn:.4f}\")\n",
    "print(f\"Sentence-BERT + CNN:  accuracy test = {acc_test_bert_cnn:.4f}\")\n",
    "print(f\"\\nBaseline mayoría ('{major_class}') en TEST: accuracy = {baseline_acc:.4f}\")\n",
    "\n",
    "print(\"\\nRESUMEN FINAL - TRANSFORMER FINE-TUNED\")\n",
    "print(f\"Transformer ({transformer_model_name}): accuracy test = {acc_test_transformer:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\nBASELINE LÉXICA\")\n",
    "\n",
    "def lexical_baseline_label(text, label_encoder, majority_label):\n",
    "\n",
    "    t = str(text).lower()\n",
    "\n",
    "    labels = set(label_encoder.classes_)\n",
    "\n",
    "    if \"query\" in labels and (\"?\" in t or any(x in t for x in [\"what\", \"why\", \"how\", \"who\"])):\n",
    "        return \"query\"\n",
    "\n",
    "    deny_keywords = [\"fake\", \"hoax\", \"not true\", \"false\", \"lie\", \"lies\", \"debunk\"]\n",
    "    if \"deny\" in labels and any(kw in t for kw in deny_keywords):\n",
    "        return \"deny\"\n",
    "\n",
    "    support_keywords = [\"true\", \"confirmed\", \"definitely\", \"for sure\", \"proved\"]\n",
    "    if \"support\" in labels and any(kw in t for kw in support_keywords):\n",
    "        return \"support\"\n",
    "\n",
    "    fact_check_domains = [\"snopes.com\", \"politifact.com\", \"factcheck.org\", \"bbc.com\", \"reuters.com\"]\n",
    "    if \"deny\" in labels and any(dom in t for dom in fact_check_domains):\n",
    "        return \"deny\"\n",
    "\n",
    "    if \"comment\" in labels:\n",
    "        return \"comment\"\n",
    "\n",
    "    return majority_label\n",
    "\n",
    "\n",
    "y_test_lexical = np.array([\n",
    "    lexical_baseline_label(txt, label_encoder, major_class) for txt in X_test_text\n",
    "])\n",
    "\n",
    "print(\"\\nResultados baseline léxica sobre TEST:\")\n",
    "acc_lex = accuracy_score(y_test, y_test_lexical)\n",
    "print(f\"Accuracy baseline léxica = {acc_lex:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report (TEST) - Baseline léxica:\")\n",
    "print(classification_report(y_test, y_test_lexical, digits=4))\n",
    "\n",
    "print(\"\\nEjemplo de predicciones (primeros 20 ejemplos del TEST):\")\n",
    "for i in range(20):\n",
    "    print(f\"{i}) texto={X_test_text[i][:60]!r}...\")\n",
    "    print(f\"   real     = {y_test[i]}\")\n",
    "    print(f\"   pred_lex = {y_test_lexical[i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rumourenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
